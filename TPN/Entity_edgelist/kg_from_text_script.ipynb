{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963c8478-f33a-4217-86ea-3c42911c0b1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:08.130582Z",
     "iopub.status.busy": "2022-10-03T20:00:08.129574Z",
     "iopub.status.idle": "2022-10-03T20:00:16.652588Z",
     "shell.execute_reply": "2022-10-03T20:00:16.651606Z",
     "shell.execute_reply.started": "2022-10-03T20:00:08.130582Z"
    },
    "id": "BrcXpPzTSszu",
    "outputId": "4af118e9-57bc-4313-f930-9c2348d2f219",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gcmar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Add rebel component https://github.com/Babelscape/rebel/blob/main/spacy_component.py\n",
    "import spacy\n",
    "import crosslingual_coreference\n",
    "import requests\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from spacy import Language\n",
    "from typing import List\n",
    "from spacy.tokens import Doc, Span\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63af62f8-d9d2-43f8-8464-f73aaee85eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:16.653596Z",
     "iopub.status.busy": "2022-10-03T20:00:16.653596Z",
     "iopub.status.idle": "2022-10-03T20:00:16.683590Z",
     "shell.execute_reply": "2022-10-03T20:00:16.682585Z",
     "shell.execute_reply.started": "2022-10-03T20:00:16.653596Z"
    },
    "id": "cGsgtd8lxhVo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_wiki_api(item):\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&language=en&format=json\"\n",
    "        data = requests.get(url).json()\n",
    "        # Return the first id (Could upgrade this in the future)\n",
    "        return data['search'][0]['id']\n",
    "    except:\n",
    "        return 'id-less'\n",
    "\n",
    "def extract_triplets(text):\n",
    "    \"\"\"\n",
    "    Function to parse the generated text and extract the triplets\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "\n",
    "    return triplets\n",
    "\n",
    "\n",
    "@Language.factory(\n",
    "    \"rebel\",\n",
    "    requires=[\"doc.sents\"],\n",
    "    assigns=[\"doc._.rel\"],\n",
    "    default_config={\n",
    "        \"model_name\": \"Babelscape/rebel-large\",\n",
    "        \"device\": 0,\n",
    "    },\n",
    ")\n",
    "class RebelComponent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nlp,\n",
    "        name,\n",
    "        model_name: str,\n",
    "        device: int,\n",
    "    ):\n",
    "        assert model_name is not None, \"\"\n",
    "        self.triplet_extractor = pipeline(\"text2text-generation\", model=model_name, tokenizer=model_name, device=device)\n",
    "        self.entity_mapping = {}\n",
    "        # Register custom extension on the Doc\n",
    "        if not Doc.has_extension(\"rel\"):\n",
    "            Doc.set_extension(\"rel\", default={})\n",
    "\n",
    "    def get_wiki_id(self, item: str):\n",
    "        mapping = self.entity_mapping.get(item)\n",
    "        if mapping:\n",
    "            return mapping\n",
    "        else:\n",
    "            res = call_wiki_api(item)\n",
    "            self.entity_mapping[item] = res\n",
    "            return res\n",
    "\n",
    "    \n",
    "    def _generate_triplets(self, sent: Span) -> List[dict]:\n",
    "        output_ids = self.triplet_extractor(sent.text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"][\"output_ids\"]\n",
    "        extracted_text = self.triplet_extractor.tokenizer.batch_decode(output_ids[0])\n",
    "        extracted_triplets = extract_triplets(extracted_text[0])\n",
    "        return extracted_triplets\n",
    "\n",
    "    def set_annotations(self, doc: Doc, triplets: List[dict]):\n",
    "        for triplet in triplets:\n",
    "\n",
    "            # Remove self-loops (relationships that start and end at the entity)\n",
    "            if triplet['head'] == triplet['tail']:\n",
    "                continue\n",
    "\n",
    "            # Use regex to search for entities\n",
    "            head_span = re.search(triplet[\"head\"], doc.text)\n",
    "            tail_span = re.search(triplet[\"tail\"], doc.text)\n",
    "\n",
    "            # Skip the relation if both head and tail entities are not present in the text\n",
    "            # Sometimes the Rebel model hallucinates some entities\n",
    "            if not head_span or not tail_span:\n",
    "                continue\n",
    "\n",
    "            index = hashlib.sha1(\"\".join([triplet['head'], triplet['tail'], triplet['type']]).encode('utf-8')).hexdigest()\n",
    "            if index not in doc._.rel:\n",
    "                # Get wiki ids and store results\n",
    "                doc._.rel[index] = {\"relation\": triplet[\"type\"], \"head_span\": {'text': triplet['head'], 'id': self.get_wiki_id(triplet['head'])}, \"tail_span\": {'text': triplet['tail'], 'id': self.get_wiki_id(triplet['tail'])}}\n",
    "\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        for sent in doc.sents:\n",
    "            sentence_triplets = self._generate_triplets(sent)\n",
    "            self.set_annotations(doc, sentence_triplets)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1241c1d-d664-4897-9af5-87facc47b718",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:16.685581Z",
     "iopub.status.busy": "2022-10-03T20:00:16.684581Z",
     "iopub.status.idle": "2022-10-03T20:00:38.730164Z",
     "shell.execute_reply": "2022-10-03T20:00:38.730164Z",
     "shell.execute_reply.started": "2022-10-03T20:00:16.685581Z"
    },
    "id": "SSTDfj3nSSca",
    "outputId": "0dbdbb3c-7a6c-46a3-8b9e-dc89f8af7486",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\gcmar\\AppData\\Local\\Temp\\tmp8a4fzgnt\\config.json as plain json\n",
      "Some weights of the model checkpoint at nreimers/mMiniLMv2-L12-H384-distilled-from-XLMR-Large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at nreimers/mMiniLMv2-L12-H384-distilled-from-XLMR-Large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RebelComponent at 0x1a8b2f47fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 0 # Number of the GPU, -1 if want to use CPU\n",
    "\n",
    "# Add coreference resolution model\n",
    "coref = spacy.load('en_core_web_sm', disable=['ner', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer'])\n",
    "coref.add_pipe(\"xx_coref\", \n",
    "    config={\"chunk_size\": 2500, \n",
    "            \"chunk_overlap\": 2, \n",
    "            \"device\": DEVICE}\n",
    "              )\n",
    "\n",
    "# Define rel extraction model\n",
    "rel_ext = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer', 'attribute_rules', 'tagger'])\n",
    "rel_ext.add_pipe(\"rebel\", \n",
    "                 config={\n",
    "                     'device':DEVICE,\n",
    "                     'model_name':'Babelscape/rebel-large'} # Model used, will default to 'Babelscape/rebel-large' if not given\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b0524a-a834-4e5f-995a-e20c9f5a2b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:38.731165Z",
     "iopub.status.busy": "2022-10-03T20:00:38.731165Z",
     "iopub.status.idle": "2022-10-03T20:00:38.746165Z",
     "shell.execute_reply": "2022-10-03T20:00:38.746165Z",
     "shell.execute_reply.started": "2022-10-03T20:00:38.731165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crosslingual_coreference implementation\n",
    "def coref_res(text_series):\n",
    "    coref_text_series = text_series.apply(lambda x : coref(x)._.resolved_text)\n",
    "    return(coref_text_series)\n",
    "\n",
    "# # choose minilm for speed/memory and info_xlm for accuracy\n",
    "# predictor = Predictor(\n",
    "#     language=\"en_core_web_sm\", device=-1, model_name=\"minilm\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c9b2b0-fc17-4219-a3f2-7814f71e1c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:38.748173Z",
     "iopub.status.busy": "2022-10-03T20:00:38.748173Z",
     "iopub.status.idle": "2022-10-03T20:00:38.763175Z",
     "shell.execute_reply": "2022-10-03T20:00:38.762164Z",
     "shell.execute_reply.started": "2022-10-03T20:00:38.748173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def link_entities_text(text):\n",
    "    try:\n",
    "        ent_rel_lst = list(rel_ext(text)._.rel.values())\n",
    "    except:\n",
    "        print(\"Could not extract relationships for text\")\n",
    "        ent_rel_lst = [{'relation': 'rel_err',\n",
    "                        'head_span': {'text': 'rel_err', 'id': 'rel_err'},\n",
    "                        'tail_span': {'text': 'rel_err', 'id': 'rel_err'}}]\n",
    "        \n",
    "    entity_df = pd.DataFrame()\n",
    "    rel_lst = []\n",
    "    head_text_lst = []\n",
    "    head_wiki_id_lst = []\n",
    "    tail_text_lst = []\n",
    "    tail_wiki_id_lst = []\n",
    "    for i in range(len(ent_rel_lst)):\n",
    "        rel_lst.append(ent_rel_lst[i]['relation'])\n",
    "        head_text_lst.append(ent_rel_lst[i]['head_span']['text'])\n",
    "        head_wiki_id_lst.append(ent_rel_lst[i]['head_span']['id'])\n",
    "        tail_text_lst.append(ent_rel_lst[i]['tail_span']['text'])\n",
    "        tail_wiki_id_lst.append(ent_rel_lst[i]['tail_span']['id'])\n",
    "    entity_df['head_text'] = head_text_lst\n",
    "    entity_df['head_wiki_id'] = head_wiki_id_lst\n",
    "    entity_df['relation'] = rel_lst\n",
    "    entity_df['tail_text'] = tail_text_lst\n",
    "    entity_df['tail_wiki_id'] = tail_wiki_id_lst\n",
    "    return(entity_df)\n",
    "\n",
    "def link_entities(text_series):\n",
    "    entity_df_series = text_series.apply(lambda x : link_entities_text(x))\n",
    "    return(entity_df_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241dfc60-ff99-45d9-91cb-3638ff41236b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:38.764168Z",
     "iopub.status.busy": "2022-10-03T20:00:38.764168Z",
     "iopub.status.idle": "2022-10-03T20:00:39.415168Z",
     "shell.execute_reply": "2022-10-03T20:00:39.414167Z",
     "shell.execute_reply.started": "2022-10-03T20:00:38.764168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author(s) ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Art. No.</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>...</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>CODEN</th>\n",
       "      <th>PubMed ID</th>\n",
       "      <th>Language of Original Document</th>\n",
       "      <th>Abbreviated Source Title</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Publication Stage</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>Source</th>\n",
       "      <th>EID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wetzel M.C., Stuart D.G.</td>\n",
       "      <td>7006494575;57203057621;</td>\n",
       "      <td>Ensemble characterivstics ofcat locovmotionand...</td>\n",
       "      <td>1976</td>\n",
       "      <td>Progress in Neurobiology</td>\n",
       "      <td>7</td>\n",
       "      <td>PART 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PGNBA</td>\n",
       "      <td>785547.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Prog. Neurobiol.</td>\n",
       "      <td>Review</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-0017165063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jenkins E.W.</td>\n",
       "      <td>14325242300;</td>\n",
       "      <td>Some Sources for the history of science educat...</td>\n",
       "      <td>1980</td>\n",
       "      <td>Studies in Science Education</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Stud. Sci. Educ.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84947353367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOORE D., PENIKAS J., RANKIN M.A.</td>\n",
       "      <td>55197635600;6504171017;7006868718;</td>\n",
       "      <td>Regional specialization for an optomotor respo...</td>\n",
       "      <td>1981</td>\n",
       "      <td>Physiological Entomology</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Physiol.Entomol.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84981620126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fernald R.D.</td>\n",
       "      <td>7006718987;</td>\n",
       "      <td>Neuroethology according to Hoyle</td>\n",
       "      <td>1984</td>\n",
       "      <td>Behavioral and Brain Sciences</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>387</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Behav. Brain Sci.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84974510172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erber J.</td>\n",
       "      <td>7006073714;</td>\n",
       "      <td>Neuroethology or motorethology?</td>\n",
       "      <td>1984</td>\n",
       "      <td>Behavioral and Brain Sciences</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Behav. Brain Sci.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84974505693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>Ryu S., Kim S.-C.</td>\n",
       "      <td>55561499900;57007270300;</td>\n",
       "      <td>Knocking and listening: Learning mechanical im...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sensors (Switzerland)</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31936449.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold, Green</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85077845047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>Lhomme P., Williams S.D., Ghisbain G., Martine...</td>\n",
       "      <td>24577383300;57259021000;57210204005;5662285280...</td>\n",
       "      <td>Diversification pattern of the widespread hola...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Insect Systematics and Diversity</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Insect Syst. Divers.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Hybrid Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85106259106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>Srikanth R., Rekha K.S., Kiran D.R., Raju P.V.</td>\n",
       "      <td>57222598784;57209336734;57222597171;57222605271;</td>\n",
       "      <td>Use of artificial intelligence in IPM</td>\n",
       "      <td>2020</td>\n",
       "      <td>Indian Journal of Entomology</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>616</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Indian. J. Entomol.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85103391838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>Shi Z., Dang H., Liu Z., Zhou X.</td>\n",
       "      <td>57201977457;57200641138;57201996356;9746372900;</td>\n",
       "      <td>Detection and identification of stored-grain i...</td>\n",
       "      <td>2020</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163703</td>\n",
       "      <td>163714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>IEEE Access</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85102839536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>Kouakou B.K., Jansson S., Brydegaard M., Zoueu...</td>\n",
       "      <td>57221528287;57188957342;25957905600;12240856500;</td>\n",
       "      <td>Entomological Scheimpflug lidar for estimating...</td>\n",
       "      <td>2020</td>\n",
       "      <td>OSA Continuum</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2362</td>\n",
       "      <td>2371</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>OSA Contin.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85100926044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4333 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Authors  \\\n",
       "0                              Wetzel M.C., Stuart D.G.   \n",
       "1                                          Jenkins E.W.   \n",
       "2                     MOORE D., PENIKAS J., RANKIN M.A.   \n",
       "3                                          Fernald R.D.   \n",
       "4                                              Erber J.   \n",
       "...                                                 ...   \n",
       "4328                                  Ryu S., Kim S.-C.   \n",
       "4329  Lhomme P., Williams S.D., Ghisbain G., Martine...   \n",
       "4330     Srikanth R., Rekha K.S., Kiran D.R., Raju P.V.   \n",
       "4331                   Shi Z., Dang H., Liu Z., Zhou X.   \n",
       "4332  Kouakou B.K., Jansson S., Brydegaard M., Zoueu...   \n",
       "\n",
       "                                           Author(s) ID  \\\n",
       "0                               7006494575;57203057621;   \n",
       "1                                          14325242300;   \n",
       "2                    55197635600;6504171017;7006868718;   \n",
       "3                                           7006718987;   \n",
       "4                                           7006073714;   \n",
       "...                                                 ...   \n",
       "4328                           55561499900;57007270300;   \n",
       "4329  24577383300;57259021000;57210204005;5662285280...   \n",
       "4330   57222598784;57209336734;57222597171;57222605271;   \n",
       "4331    57201977457;57200641138;57201996356;9746372900;   \n",
       "4332   57221528287;57188957342;25957905600;12240856500;   \n",
       "\n",
       "                                                  Title  Year  \\\n",
       "0     Ensemble characterivstics ofcat locovmotionand...  1976   \n",
       "1     Some Sources for the history of science educat...  1980   \n",
       "2     Regional specialization for an optomotor respo...  1981   \n",
       "3                      Neuroethology according to Hoyle  1984   \n",
       "4                       Neuroethology or motorethology?  1984   \n",
       "...                                                 ...   ...   \n",
       "4328  Knocking and listening: Learning mechanical im...  2020   \n",
       "4329  Diversification pattern of the widespread hola...  2020   \n",
       "4330              Use of artificial intelligence in IPM  2020   \n",
       "4331  Detection and identification of stored-grain i...  2020   \n",
       "4332  Entomological Scheimpflug lidar for estimating...  2020   \n",
       "\n",
       "                          Source title Volume   Issue Art. No. Page start  \\\n",
       "0             Progress in Neurobiology      7  PART 1      NaN          1   \n",
       "1         Studies in Science Education      7       1      NaN         27   \n",
       "2             Physiological Entomology      6       1      NaN         61   \n",
       "3        Behavioral and Brain Sciences      7       3      NaN        387   \n",
       "4        Behavioral and Brain Sciences      7       3      NaN        386   \n",
       "...                                ...    ...     ...      ...        ...   \n",
       "4328             Sensors (Switzerland)     20       2      369        NaN   \n",
       "4329  Insect Systematics and Diversity      5       2        5        NaN   \n",
       "4330      Indian Journal of Entomology     82       4      NaN        609   \n",
       "4331                       IEEE Access      8     NaN      NaN     163703   \n",
       "4332                     OSA Continuum      3       9      NaN       2362   \n",
       "\n",
       "     Page end  ... ISBN  CODEN   PubMed ID Language of Original Document  \\\n",
       "0          98  ...  NaN  PGNBA    785547.0                       English   \n",
       "1          86  ...  NaN    NaN         NaN                       English   \n",
       "2          69  ...  NaN    NaN         NaN                       English   \n",
       "3         388  ...  NaN    NaN         NaN                       English   \n",
       "4         NaN  ...  NaN    NaN         NaN                       English   \n",
       "...       ...  ...  ...    ...         ...                           ...   \n",
       "4328      NaN  ...  NaN    NaN  31936449.0                       English   \n",
       "4329      NaN  ...  NaN    NaN         NaN                       English   \n",
       "4330      616  ...  NaN    NaN         NaN                       English   \n",
       "4331   163714  ...  NaN    NaN         NaN                       English   \n",
       "4332     2371  ...  NaN    NaN         NaN                       English   \n",
       "\n",
       "     Abbreviated Source Title Document Type Publication Stage  \\\n",
       "0            Prog. Neurobiol.        Review             Final   \n",
       "1            Stud. Sci. Educ.       Article             Final   \n",
       "2            Physiol.Entomol.       Article             Final   \n",
       "3           Behav. Brain Sci.       Article             Final   \n",
       "4           Behav. Brain Sci.       Article             Final   \n",
       "...                       ...           ...               ...   \n",
       "4328                  Sensors       Article             Final   \n",
       "4329     Insect Syst. Divers.       Article             Final   \n",
       "4330      Indian. J. Entomol.       Article             Final   \n",
       "4331              IEEE Access       Article             Final   \n",
       "4332              OSA Contin.       Article             Final   \n",
       "\n",
       "                       Open Access  Source                 EID  \n",
       "0                              NaN  Scopus   2-s2.0-0017165063  \n",
       "1                              NaN  Scopus  2-s2.0-84947353367  \n",
       "2                              NaN  Scopus  2-s2.0-84981620126  \n",
       "3                              NaN  Scopus  2-s2.0-84974510172  \n",
       "4                              NaN  Scopus  2-s2.0-84974505693  \n",
       "...                            ...     ...                 ...  \n",
       "4328  All Open Access, Gold, Green  Scopus  2-s2.0-85077845047  \n",
       "4329  All Open Access, Hybrid Gold  Scopus  2-s2.0-85106259106  \n",
       "4330                           NaN  Scopus  2-s2.0-85103391838  \n",
       "4331         All Open Access, Gold  Scopus  2-s2.0-85102839536  \n",
       "4332         All Open Access, Gold  Scopus  2-s2.0-85100926044  \n",
       "\n",
       "[4333 rows x 54 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('C:\\\\Users\\\\gcmar\\\\Desktop\\\\GIT_REPOS\\\\LAB\\\\Literature_summary\\\\TPN\\\\Entity_edgelist\\\\entomology_machine_learning.csv',sep=';')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b2f9c9-0580-4015-a0d5-f61738c54de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:39.417167Z",
     "iopub.status.busy": "2022-10-03T20:00:39.416165Z",
     "iopub.status.idle": "2022-10-03T20:00:39.477172Z",
     "shell.execute_reply": "2022-10-03T20:00:39.476176Z",
     "shell.execute_reply.started": "2022-10-03T20:00:39.417167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'(', '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'(', '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r')', '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r')', '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r\"'\", '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r\"'\", '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'\"', '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'\"', '')\n",
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\412532311.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "# data_df = pd.read_csv('E:\\GIT_REPOS\\LAB\\Literature_summary\\TPN\\Papers\\\\scopus.csv')\n",
    "data_df = data_df[data_df[\"Abstract\"] != '[No abstract available]']\n",
    "data_df.reset_index(inplace=True, drop=True)\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'(', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r')', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r\"'\", '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r\"'\", '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'\"', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'\"', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d36c245-8c59-4c34-8ec0-f4661faf0cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T20:00:39.478171Z",
     "iopub.status.busy": "2022-10-03T20:00:39.478171Z",
     "iopub.status.idle": "2022-10-03T22:24:18.893784Z",
     "shell.execute_reply": "2022-10-03T22:24:18.891806Z",
     "shell.execute_reply.started": "2022-10-03T20:00:39.478171Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coref done 0\n",
      "entity linking done 0\n",
      "df create done 0\n",
      "df to list done 0 \n",
      "\n",
      "coref done 100\n",
      "entity linking done 100\n",
      "df create done 100\n",
      "df to list done 100 \n",
      "\n",
      "coref done 200\n",
      "entity linking done 200\n",
      "df create done 200\n",
      "df to list done 200 \n",
      "\n",
      "coref done 300\n",
      "entity linking done 300\n",
      "df create done 300\n",
      "df to list done 300 \n",
      "\n",
      "coref done 400\n",
      "entity linking done 400\n",
      "df create done 400\n",
      "df to list done 400 \n",
      "\n",
      "coref done 500\n",
      "entity linking done 500\n",
      "df create done 500\n",
      "df to list done 500 \n",
      "\n",
      "coref done 600\n",
      "entity linking done 600\n",
      "df create done 600\n",
      "df to list done 600 \n",
      "\n",
      "coref done 700\n",
      "entity linking done 700\n",
      "df create done 700\n",
      "df to list done 700 \n",
      "\n",
      "coref done 800\n",
      "entity linking done 800\n",
      "df create done 800\n",
      "df to list done 800 \n",
      "\n",
      "coref done 900\n",
      "entity linking done 900\n",
      "df create done 900\n",
      "df to list done 900 \n",
      "\n",
      "coref done 1000\n",
      "entity linking done 1000\n",
      "df create done 1000\n",
      "df to list done 1000 \n",
      "\n",
      "coref done 1100\n",
      "entity linking done 1100\n",
      "df create done 1100\n",
      "df to list done 1100 \n",
      "\n",
      "coref done 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gcmar\\AppData\\Local\\Temp\\ipykernel_23940\\4235504974.py:94: FutureWarning: Possible nested set at position 6\n",
      "  head_span = re.search(triplet[\"head\"], doc.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not extract relationships for text\n",
      "Could not extract relationships for text\n",
      "entity linking done 1200\n",
      "df create done 1200\n",
      "df to list done 1200 \n",
      "\n",
      "coref done 1300\n",
      "entity linking done 1300\n",
      "df create done 1300\n",
      "df to list done 1300 \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m entities_df_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_point, \u001b[38;5;28mlen\u001b[39m(data_df), win_size):\n\u001b[1;32m----> 6\u001b[0m     coref_series \u001b[38;5;241m=\u001b[39m \u001b[43mcoref_res\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAbstract\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mwin_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoref done\u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n\u001b[0;32m      8\u001b[0m     link_entities_series \u001b[38;5;241m=\u001b[39m link_entities(text_series\u001b[38;5;241m=\u001b[39mcoref_series)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mcoref_res\u001b[1;34m(text_series)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoref_res\u001b[39m(text_series):\n\u001b[1;32m----> 3\u001b[0m     coref_text_series \u001b[38;5;241m=\u001b[39m \u001b[43mtext_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolved_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(coref_text_series)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\pandas\\core\\series.py:4774\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4666\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4669\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4670\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4671\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4672\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4673\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4772\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4773\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\pandas\\core\\apply.py:1100\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\pandas\\core\\apply.py:1151\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1150\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1151\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2919\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mcoref_res.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoref_res\u001b[39m(text_series):\n\u001b[1;32m----> 3\u001b[0m     coref_text_series \u001b[38;5;241m=\u001b[39m text_series\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[43mcoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_\u001b[38;5;241m.\u001b[39mresolved_text)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(coref_text_series)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\spacy\\language.py:1025\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1025\u001b[0m     \u001b[43merror_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE005\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\spacy\\util.py:1658\u001b[0m, in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[1;32m-> 1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\spacy\\language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1020\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\crosslingual_coreference\\CrossLingualPredictorSpacy.py:33\u001b[0m, in \u001b[0;36mCrossLingualPredictorSpacy.__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc: Doc) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    predict the class for a spacy Doc\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m        Doc: spacy doc with ._.cats key-class proba-value dict\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_prediction_to_doc(doc, prediction)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\crosslingual_coreference\\CrossLingualPredictor.py:105\u001b[0m, in \u001b[0;36mCrossLingualPredictor.predict\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    103\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39m_spacy(text)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size:\n\u001b[1;32m--> 105\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_sentencized_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [text]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NET\\lib\\site-packages\\crosslingual_coreference\\CrossLingualPredictor.py:193\u001b[0m, in \u001b[0;36mCrossLingualPredictor.chunk_sentencized_doc\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Check if the last chunk is too short. If it is, add it to the previous chunk\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp_chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp_chunk[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 193\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mextend(temp_chunk[:])\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(temp_chunk[:])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "win_size = 100\n",
    "start_point = 0 # default to 0\n",
    "# coref_lst = []\n",
    "entities_df_lst = []\n",
    "for i in range(start_point, len(data_df), win_size):\n",
    "    coref_series = coref_res(text_series=data_df[\"Abstract\"].iloc[i:i+win_size])\n",
    "    print('coref done', i)\n",
    "    link_entities_series = link_entities(text_series=coref_series)\n",
    "    print('entity linking done', i)\n",
    "    entities_df = pd.concat(link_entities_series.tolist())\n",
    "    print('df create done', i)\n",
    "    entities_df_lst.append(entities_df)\n",
    "    print('df to list done', i, '\\n')\n",
    "all_entities_df = pd.concat(entities_df_lst)\n",
    "all_entities_df.reset_index(drop=True, inplace=True)\n",
    "edge_lst_df = all_entities_df.value_counts().reset_index().rename(columns={0: \"count\"})\n",
    "edge_lst_df.to_csv('entity_weighted_edgelist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3babaf-6763-4262-9bab-116ad5a4419e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-03T22:24:18.894779Z",
     "iopub.status.idle": "2022-10-03T22:24:18.894779Z",
     "shell.execute_reply": "2022-10-03T22:24:18.894779Z",
     "shell.execute_reply.started": "2022-10-03T22:24:18.894779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coref_series = coref_res(text_series=data_df[\"Abstract\"][:1000])\n",
    "# link_entities_series = link_entities(text_series=coref_series)\n",
    "# all_entities_df = pd.concat(link_entities_series.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
